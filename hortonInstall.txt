####SETUP ISILON view and validate process
(see bottom of file for just commands)


isi license list
isi license activate --key ISILO-HJXC0-H15JU-YTZTW-OKZLT
isi license activate --key ISILO-HVOC0-PHOJU-YPATW-W4FKT
isi license list


isi zone zones create --name=zone1-hdp --path=/ifs/zone1/hdp --create-path
isi zone zones list --verbose


mkdir -p /ifs/zone1/hdp/hadoop-root
ls -al /ifs/zone1/hdp



isi network subnets list --verbose
isi network subnets modify groupnet0.subnet0 --sc-service-addr=192.168.1.100


isi network pools list --verbose
isi network pools create --id=groupnet0:subnet0:hadoop-pool-hdp --ranges=192.168.1.60-192.168.1.68  --access-zone=zone1-hdp  --alloc-method=dynamic  --ifaces=1-4:ext-1 --sc-subnet=subnet0  --sc-dns-zone=isilonsczone-hdp.vlab.local    --description=hadoop


isi network pools list --verbose
isi network pools view --id=groupnet0:subnet0:hadoop-pool-hdp





###################################################################################################
####SETUP windows DNS for SmartConnect Zone

#connect to domain controller DC
#admin tools DNS
#select vlab.local
add A record   ssip-isilon  192.168.1.100

#new delegation
	isilonsczone-hdp
#Add
	ssip-isilon.vlab.local
#Resolve, comes back as 192.168.1.100
#complete



#TEST SCZone
ping isilonsczone-hdp.vlab.local

#should resolve to 192.168.1.60-68

###################################################################################################



####Isilon HDFS Settings:
isi hdfs settings view --zone=zone1-hdp
isi hdfs settings modify --zone=zone1-hdp --root-directory=/ifs/zone1/hdp/hadoop-root
isi zone zones modify --user-mapping-rules="hdfs=>root" --zone=zone1-hdp
isi hdfs settings modify --zone=zone1-hdp --ambari-namenode=isilonsczone-hdp.vlab.local
isi hdfs settings modify --zone=zone1-hdp --ambari-server=hdfs01.vlab.local

touch /ifs/zone1/hdp/hadoop-root/THIS_IS_ISILON_zone1-hdp.txt

isi auth settings acls modify --group-owner-inheritance=parent




####HDFS Users & Group setup
mkdir -p /ifs/zone1/hdp/scripts

https://github.com/Isilon/isilon_hadoop_tools

#clone or download, as a zip, go find the download, unzip
#winscp the isilon_create_users.sh & isilon_create_directories.sh  to /ifs/zone1/hdp/scripts

cd /ifs/zone1/hdp/scripts
wget https://raw.githubusercontent.com/Isilon/isilon_hadoop_tools/master/isilon_create_users.sh --no-check-certificate
wget https://raw.githubusercontent.com/Isilon/isilon_hadoop_tools/master/isilon_create_directories.sh --no-check-certificate

chmod u+x *

bash isilon_create_users.sh --dist hwx --startuid 501 --startgid 501  --zone zone1-hdp

bash isilon_create_directories.sh --dist hwx --zone zone1-hdp  --fixperm

ls -al /ifs/zone1/hdp/hadoop-root
ls -al /ifs/zone1/hdp/hadoop-root/user




####on Isilon
cat zone1-hdp.passwd
cat zone1-hdp.group

#go to HDFS01
vi /etc/passwd
#G
#o
#cut and paste content from zone1-hdp.passwd
esc :wq

vi /etc/group
#G
#o
#cut and paste content from zone1-hdp.group
esc :wq



#go to HDFS02
vi /etc/passwd
#G
#o
#cut and paste content from zone1-hdp.passwd
esc :wq

vi /etc/group
#G
#o
#cut and paste content from zone1-hdp.group
esc :wq




#go to HDFS03
vi /etc/passwd
#G
#o
#cut and paste content from zone1-hdp.passwd
esc :wq

vi /etc/group
#G
#o
#cut and paste content from zone1-hdp.group
esc :wq



##on all hosts add the folowing home



mkdir /home/httpfs
mkdir /home/apache
mkdir /home/kafka
mkdir /home/kms
mkdir /home/kudu
mkdir /home/llama
mkdir /home/oozie
mkdir /home/solr
mkdir /home/spark
mkdir /home/sqoop
mkdir /home/zookeeper
mkdir /home/anonymous

mkdir /home/accumulo
mkdir /home/flume
mkdir /home/hdfs
mkdir /home/mapred
mkdir /home/yarn
mkdir /home/HTTP
mkdir /home/hbase
mkdir /home/hive
mkdir /home/storm
mkdir /home/falcon
mkdir /home/tracer
mkdir /home/tez
mkdir /home/hcat
mkdir /home/ambari-qa
mkdir /home/hue
mkdir /home/hadoopqa
mkdir /home/mahout
mkdir /home/ranger
mkdir /home/atlas
mkdir /home/ams
mkdir /home/zepplin
mkdir /home/livy
mkdir /home/logsearch
mkdir /home/infra-solr
mkdir /home/activity_analyzer
mkdir /home/knox
mkdir /home/ambari-server
mkdir /home/admin
mkdir /home/activity_explorer

chown hdfs:hdfs /home/hdfs
chown mapred:mapred /home/mapred
chown yarn:yarn /home/yarn
chown HTTP:HTTP /home/HTTP
chown hbase:hbase /home/hbase
chown hive:hive /home/hive
chown accumulo:accumulo /home/accumulo
chown flume:flume /home/flume
chown httpfs:httpfs /home/httpfs
chown apache:apache /home/apache
chown kafka:kafka /home/kafka
chown oozie:oozie /home/oozie
chown spark:spark /home/spark
chown sqoop:sqoop /home/sqoop
chown zookeeper:zookeeper /home/zookeeper
chown anonymous:anonymous /home/anonymous
chown storm:storm /home/storm
chown falcon:falcon /home/falcon
chown tracer:tracer /home/tracer
chown tez:tez /home/tez
chown hcat:hcat /home/hcat
chown ambari-qa:ambari-qa /home/ambari-qa
chown hue:hue /home/hue
chown hadoopqa:hadoopqa /home/hadoopqa
chown mahout:mahout /home/mahout
chown ranger:ranger /home/ranger
chown atlas:atlas /home/atlas
chown ams:ams /home/ams
chown zepplin:zepplin /home/zepplin
chown livy:livy /home/livy
chown logsearch:logsearch /home/logsearch
chown infra-solr:infra-solr /home/infra-solr
chown activity_analyzer:activity_analyzer /home/activity_analyzer
chown knox:knox /home/knox
chown ambari-server:ambari-server home/ambari-server
chown admin:admin /home/admin
chown activity_explorer:activity_explorer /home/activity_explorer



chmod 700 /home/hdfs
chmod 700 /home/mapred
chmod 700 /home/yarn
chmod 700 /home/HTTP
chmod 700 /home/hbase
chmod 700 /home/hive
chmod 700 /home/accumulo
chmod 700 /home/flume
chmod 700 /home/httpfs
chmod 700 /home/apache
chmod 700 /home/kafka
chmod 700 /home/oozie
chmod 700 /home/spark
chmod 700 /home/sqoop
chmod 700 /home/zookeeper
chmod 700 /home/anonymous
chmod 700 /home/accumulo
chmod 700 /home/flume
chmod 700 /home/hdfs
chmod 700 /home/mapred
chmod 700 /home/yarn
chmod 700 /home/HTTP
chmod 700 /home/hbase
chmod 700 /home/hive
chmod 700 /home/storm
chmod 700 /home/falcon
chmod 700 /home/tracer
chmod 700 /home/tez
chmod 700 /home/hcat
chmod 700 /home/ambari-qa
chmod 700 /home/hue
chmod 700 /home/hadoopqa
chmod 700 /home/mahout
chmod 700 /home/ranger
chmod 700 /home/atlas
chmod 700 /home/ams
chmod 700 /home/zepplin
chmod 700 /home/livy
chmod 700 /home/logsearch
chmod 700 /home/infra-solr
chmod 700 /home/activity_analyzer
chmod 700 /home/knox
chmod 700 /home/ambari-server
chmod 700 /home/admin
chmod 700 /home/activity_explorer


****************************************************************************
##Ambari & HDP Install

##Change Hostname to lower case & update DNS

vi /etc/sysconfig/network

##Linux HOST setup:
SELinux
	vi /etc/selinux/config 
	SELINUX=disabled

	
#IPtables off
yum -y install ntp

chkconfig iptables off
chkconfig ip6tables off
chkconfig ntpdate on
chkconfig
chkconfig ntpd on
service ntpd start
ntpq -np

#Ambari Host inspector fixes
echo never > /sys/kernel/mm/transparent_hugepage/defrag
echo never > /sys/kernel/mm/transparent_hugepage/enabled
echo never > /sys/kernel/mm/redhat_transparent_hugepage/defrag
echo never > /sys/kernel/mm/redhat_transparent_hugepage/enabled

#add

vi /etc/rc.local

if test -f /sys/kernel/mm/transparent_hugepage/enabled; then
   echo never > /sys/kernel/mm/transparent_hugepage/enabled
fi
if test -f /sys/kernel/mm/transparent_hugepage/defrag; then
   echo never > /sys/kernel/mm/transparent_hugepage/defrag
fi



reboot all hosts

##install Ambari on hdfs01
##install higher version initially
wget -nv http://public-repo-1.hortonworks.com/ambari/centos6/2.x/updates/2.4.0.1/ambari.repo -O /etc/yum.repos.d/ambari.repo
yum clean all


yum -y install ambari-server 
ambari-server setup

Custom users: n
JDK option: 1
Accept license : Y

Database n

ambari-server status
ambari-server start

http://ambari-server:8080   admin/admin

On ambari host

ssh-keygen

ssh-copy-id root@hdfs01.vlab.local

ssh-copy-id root@hdfs02.vlab.local

ssh-copy-id root@hdfs03.vlab.local

##test keyless ssh
ssh root@hdfs01.vlab.local
ssh root@hdfs02.vlab.local
ssh root@hdfs03.vlab.local

cat /root/.ssh/id_rsa   
##Copy into a txt file on desktop and save


Name cluster - HDP
Select stack
unselect all repos not needed
Modify redhat6 repos to use local repo:


http://192.168.1.20/hdp/HDP/centos6/2.x/updates/2.3.6.0
http://192.168.1.20/hdp/HDP-UTILS-1.1.0.20/repos/centos6


##Host to deploy
hdfs01.vlab.local
hdfs02.vlab.local
hdfs03.vlab.local

##on Ambari server, NO isilon yet

Select ssh key file from above
Register and confirm


All hosts green
BACK <---
Select Perform Manual
Add the isilon Sczonehost name in to list; isilonsczone-hdp.vlab.local
Register

All host + isilon are now green
continue


Select service to deploy
Move namenode to isilon host
Move snamenode to isilon host

move all other roles around to balance


on roles, master & slaves

datanode - ISILON host only!!
add other roles, client and master to other nodes, nothing else on isilon


##Customize Services
on HDFS configuration, customize:
dfs.namenode.http-address  change port from 50070 --> 8082
dfs.namenode.https-address change port from 50470 --> 8080
##dfs.client-write-packet-size to 131072
yarn.scheduler.capacity.node-locality-delay  to  0  



add all passwords in
continue and deploy --- >


##Test:
hadoop fs -ls /
hadoop fs -mkdir /user/hdfs/TEST50070


or just run the service check!!!!!

cd /usr/hdp/2.3.6.0-3796/hadoop-mapreduce  (the version number may differ)

yarn jar hadoop-mapreduce-examples-2.7.1.2.3.6.0-3796.jar pi 10 100

yarn jar hadoop-mapreduce-examples-2.7.1.2.3.6.0-3796.jar teragen 100000 /user/hdfs/teragenOUT
yarn jar hadoop-mapreduce-examples-2.7.1.2.3.6.0-3796.jar  terasort /user/hdfs/teragenOUT /user/hdfs/terasortOUT
yarn jar hadoop-mapreduce-examples-2.7.1.2.3.6.0-3796.jar  teravalidate /user/hdfs/terasortOUT /user/hdfs/teravalidateOUT




Just the isilon commands in one block:
#################################################################################
#################################################################################




isi license activate --key ISILO-HJXC0-H15JU-YTZTW-OKZLT
isi license activate --key ISILO-HVOC0-PHOJU-YPATW-W4FKT


#License before running


isi zone zones create --name=zone1-hdp --path=/ifs/zone1/hdp --create-path
mkdir -p /ifs/zone1/hdp/hadoop-root
isi network subnets modify groupnet0.subnet0 --sc-service-addr=192.168.1.100
isi network pools create --id=groupnet0:subnet0:hadoop-pool-hdp --ranges=192.168.1.60-192.168.1.68  --access-zone=zone1-hdp  --alloc-method=dynamic  --ifaces=1-4:ext-1 --sc-subnet=subnet0  --sc-dns-zone=isilonsczone-hdp.vlab.local    --description=hdp_hadoop_access_zone
isi hdfs settings modify --zone=zone1-hdp --root-directory=/ifs/zone1/hdp/hadoop-root
isi zone zones modify --user-mapping-rules="hdfs=>root" --zone=zone1-hdp
touch /ifs/zone1/hdp/hadoop-root/THIS_IS_ISILON_zone1-hdp.txt
isi auth settings acls modify --group-owner-inheritance=parent
mkdir -p /ifs/zone1/hdp/scripts
cd /ifs/zone1/hdp/scripts
wget https://raw.githubusercontent.com/Isilon/isilon_hadoop_tools/master/isilon_create_users.sh --no-check-certificate
wget https://raw.githubusercontent.com/Isilon/isilon_hadoop_tools/master/isilon_create_directories.sh --no-check-certificate
chmod u+x *
bash isilon_create_users.sh --dist hwx --startuid 501 --startgid 501  --zone zone1-hdp
bash isilon_create_directories.sh --dist hwx --zone zone1-hdp  --fixperm
isi hdfs settings modify --zone=zone1-hdp --ambari-namenode=isilonsczone-hdp.vlab.local




#Create SCZone before running
isi hdfs settings modify --zone=zone1-hdp --ambari-server=hdfs01.vlab.local





isi license list
isi zone zones list --verbose
isi network subnets list --verbose
isi network pools list --verbose
isi network pools view --id=groupnet0:subnet0:hadoop-pool-hdp
isi hdfs settings view --zone=zone1-hdp
ls -al /ifs/zone1/hdp/hadoop-root
ls -al /ifs/zone1/hdp/hadoop-root/user


#################################################################################
#################################################################################