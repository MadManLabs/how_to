###How to setup and configure Ambari HDP and Isilon
####SETUP ISILON view and validate process
(see bottom of file for just Ambari & HDP install commands if Isilon is configured)

###Validate HDFS licensed
isi license list


###create HDP Access Zone
isi zone zones create --name=zone1-hdp --path=/ifs/zone1/hdp --create-path
isi zone zones list --verbose

###create HDP root directory
mkdir -p /ifs/zone1/hdp/hadoop-root
ls -al /ifs/zone1/hdp

###Setup SmartConnect and networking if required; sample here
isi network subnets list --verbose
isi network subnets modify groupnet0.subnet0 --sc-service-addr=192.168.1.100

isi network pools list --verbose
isi network pools create --id=groupnet0:subnet0:hadoop-pool-hdp --ranges=192.168.1.60-192.168.1.68  --access-zone=zone1-hdp  --alloc-method=dynamic  --ifaces=1-4:ext-1 --sc-subnet=subnet0  --sc-dns-zone=isilonsczone-hdp.demo.local   --description=hadoop


isi network pools list --verbose
isi network pools view --id=groupnet0:subnet0:hadoop-pool-hdp


###################################################################################################
####SETUP windows DNS Server for SmartConnect Zone

#connect to domain controller DC
#admin tools DNS
#select demo.local
add A record   ssip-isilon  192.168.1.100

#new delegation
	isilonsczone-hdp
#Add
	ssip-isilon.demo.local
#Resolve, comes back as 192.168.1.100
#complete



#TEST SCZone
ping isilonsczone-hdp.demo.local

#should resolve to 192.168.1.60-68

###################################################################################################



####Isilon HDFS Settings:
isi hdfs settings view --zone=zone1-hdp
isi hdfs settings modify --zone=zone1-hdp --root-directory=/ifs/zone1/hdp/hadoop-root
isi zone zones modify --user-mapping-rules="hdfs=>root" --zone=zone1-hdp
isi hdfs settings modify --zone=zone1-hdp --ambari-namenode=isilonsczone-hdp.demo.local
isi hdfs settings modify --zone=zone1-hdp --ambari-server=hdfs01.demo.local

touch /ifs/zone1/hdp/hadoop-root/THIS_IS_ISILON_zone1-hdp.txt

isi auth settings acls modify --group-owner-inheritance=parent




####HDFS Users & Group setup
mkdir -p /ifs/zone1/hdp/scripts


###get the create scripts from github
https://github.com/Isilon/isilon_hadoop_tools

#clone or download, as a zip, go find the download, unzip
#winscp the isilon_create_users.sh & isilon_create_directories.sh  to /ifs/zone1/hdp/scripts


###download create scripts natively
cd /ifs/zone1/hdp/scripts
###8.1.2+ does not have wget
wget https://raw.githubusercontent.com/Isilon/isilon_hadoop_tools/master/isilon_create_users.sh --no-check-certificate
wget https://raw.githubusercontent.com/Isilon/isilon_hadoop_tools/master/isilon_create_directories.sh --no-check-certificate



###setup the scripts
chmod u+x *


###execute the create scripts
bash isilon_create_users.sh --dist hwx --startuid 501 --startgid 501  --zone zone1-hdp

bash isilon_create_directories.sh --dist hwx --zone zone1-hdp  --fixperm



####on Isilon view users
ls -al /ifs/zone1/hdp/hadoop-root
ls -al /ifs/zone1/hdp/hadoop-root/user


### cat the output from the scripts, this is used to create the users and groups on linux hosts to ensure user id parity
cat zone1-hdp.passwd
cat zone1-hdp.group

#go to HDFS01
vi /etc/passwd
#G
#o
#cut and paste content from zone1-hdp.passwd
esc :wq

vi /etc/group
#G
#o
#cut and paste content from zone1-hdp.group
esc :wq



#go to HDFS02
vi /etc/passwd
#G
#o
#cut and paste content from zone1-hdp.passwd
esc :wq

vi /etc/group
#G
#o
#cut and paste content from zone1-hdp.group
esc :wq




#go to HDFS0XYX
vi /etc/passwd
#G
#o
#cut and paste content from zone1-hdp.passwd
esc :wq

vi /etc/group
#G
#o
#cut and paste content from zone1-hdp.group
esc :wq





##on all Linux hosts add the following home

mkdir /home/httpfs
mkdir /home/apache
mkdir /home/kafka
mkdir /home/kms
mkdir /home/llama
mkdir /home/oozie
mkdir /home/solr
mkdir /home/spark
mkdir /home/sqoop
mkdir /home/zookeeper
mkdir /home/anonymous
mkdir /home/accumulo
mkdir /home/flume
mkdir /home/hdfs
mkdir /home/mapred
mkdir /home/yarn
mkdir /home/HTTP
mkdir /home/hbase
mkdir /home/hive
mkdir /home/storm
mkdir /home/falcon
mkdir /home/tracer
mkdir /home/tez
mkdir /home/hcat
mkdir /home/ambari-qa
mkdir /home/hue
mkdir /home/hadoopqa
mkdir /home/mahout
mkdir /home/ranger
mkdir /home/atlas
mkdir /home/ams
mkdir /home/zeppelin
mkdir /home/livy
mkdir /home/logsearch
mkdir /home/infra-solr
mkdir /home/activity_analyzer
mkdir /home/knox
mkdir /home/ambari-server
mkdir /home/admin
mkdir /home/activity_explorer


chown hdfs:hdfs /home/hdfs
chown mapred:mapred /home/mapred
chown yarn:yarn /home/yarn
chown HTTP:HTTP /home/HTTP
chown hbase:hbase /home/hbase
chown hive:hive /home/hive
chown kms:kms /home/kms
chown accumulo:accumulo /home/accumulo
chown flume:flume /home/flume
chown httpfs:httpfs /home/httpfs
chown apache:apache /home/apache
chown kafka:kafka /home/kafka
chown oozie:oozie /home/oozie
chown spark:spark /home/spark
chown llama:llama /home/llama
chown sqoop:sqoop /home/sqoop
chown zookeeper:zookeeper /home/zookeeper
chown anonymous:anonymous /home/anonymous
chown storm:storm /home/storm
chown falcon:falcon /home/falcon
chown tracer:tracer /home/tracer
chown tez:tez /home/tez
chown solr:solr /home/solr
chown hcat:hcat /home/hcat
chown ambari-qa:ambari-qa /home/ambari-qa
chown hue:hue /home/hue
chown hadoopqa:hadoopqa /home/hadoopqa
chown mahout:mahout /home/mahout
chown ranger:ranger /home/ranger
chown atlas:atlas /home/atlas
chown ams:ams /home/ams
chown zeppelin:zeppelin /home/zeppelin
chown livy:livy /home/livy
chown logsearch:logsearch /home/logsearch
chown infra-solr:infra-solr /home/infra-solr
chown activity_analyzer:activity_analyzer /home/activity_analyzer
chown knox:knox /home/knox
chown ambari-server:ambari-server /home/ambari-server
chown admin:admin /home/admin
chown activity_explorer:activity_explorer /home/activity_explorer


chmod 700 /home/hdfs
chmod 700 /home/mapred
chmod 700 /home/yarn
chmod 700 /home/HTTP
chmod 700 /home/hbase
chmod 700 /home/hive
chmod 700 /home/kms
chmod 700 /home/accumulo
chmod 700 /home/flume
chmod 700 /home/httpfs
chmod 700 /home/apache
chmod 700 /home/kafka
chmod 700 /home/oozie
chmod 700 /home/spark
chmod 700 /home/sqoop
chmod 700 /home/zookeeper
chmod 700 /home/anonymous
chmod 700 /home/accumulo
chmod 700 /home/flume
chmod 700 /home/hdfs
chmod 700 /home/mapred
chmod 700 /home/yarn
chmod 700 /home/HTTP
chmod 700 /home/hbase
chmod 700 /home/hive
chmod 700 /home/storm
chmod 700 /home/falcon
chmod 700 /home/tracer
chmod 700 /home/tez
chmod 700 /home/hcat
chmod 700 /home/llama
chmod 700 /home/ambari-qa
chmod 700 /home/hue
chmod 700 /home/hadoopqa
chmod 700 /home/mahout
chmod 700 /home/ranger
chmod 700 /home/atlas
chmod 700 /home/ams
chmod 700 /home/zeppelin
chmod 700 /home/livy
chmod 700 /home/logsearch
chmod 700 /home/infra-solr
chmod 700 /home/activity_analyzer
chmod 700 /home/knox
chmod 700 /home/ambari-server
chmod 700 /home/admin
chmod 700 /home/activity_explorer
chmod 700 /home/solr


****************************************************************************
##Ambari & HDP Install

yum upgrade openssl
yum -y install krb5-workstation krb5-libs openldap-clients

##Change Hostname to lower case & update DNS if needed
hostname

###Linux HOST setup:
###SELinux
vi /etc/selinux/config
 
SELINUX=disabled


###install ntp
yum -y install ntp
	

###setup services
###centos6
chkconfig iptables off
chkconfig ip6tables off
chkconfig ntpdate on
chkconfig ntpd on
service ntpd start
ntpq -np
chkconfig

###centos7
systemctl disable firewalld
systemctl stop firewalld
systemctl status firewalld
systemctl enable ntpd
systemctl start ntpd
systemctl status ntpd



#Ambari Host inspector fixes
echo never > /sys/kernel/mm/transparent_hugepage/defrag
echo never > /sys/kernel/mm/transparent_hugepage/enabled


#add transparent_hugepage startup script rhel7

vi /etc/systemd/system/disable-thp.service
###and paste there following content:

[Unit]
Description=Disable Transparent Huge Pages (THP)

[Service]
Type=simple
ExecStart=/bin/sh -c "echo 'never' > /sys/kernel/mm/transparent_hugepage/enabled && echo 'never' > /sys/kernel/mm/transparent_hugepage/defrag"

[Install]
WantedBy=multi-user.target



Save the file and reload SystemD daemon:


systemctl daemon-reload

systemctl start disable-thp
systemctl enable disable-thp


reboot all hosts

##install Ambari on hdfs01
##install higher suported version initially, older version left only for legacy installs(these chnage all the time, use the website and support matrix to determine valid version to install)
#wget -nv http://public-repo-1.hortonworks.com/ambari/centos6/2.x/updates/2.4.0.1/ambari.repo -O /etc/yum.repos.d/ambari.repo
#wget -nv http://public-repo-1.hortonworks.com/ambari/centos6/2.x/updates/2.5.0.0/ambari.repo -O /etc/yum.repos.d/ambari.rep
#wget -nv http://public-repo-1.hortonworks.com/ambari/centos6/2.x/updates/2.6.0.0/ambari.repo -O /etc/yum.repos.d/ambari.rep


wget -nv http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.6.2.2/ambari.repo -O /etc/yum.repos.d/ambari.repo
yum clean all


yum -y install ambari-server 
ambari-server setup

Custom users: n
JDK option: 1
Accept license : Y
GPL License for LZO: n

Database n



ambari-server status
ambari-server start

http://ambari-server:8080   admin/admin

On ambari host

ssh-keygen

ssh-copy-id root@hdfs1.demo.local

ssh-copy-id root@hdfs2.demo.local

ssh-copy-id root@hdfs3.demo.local

##test keyless ssh
ssh root@hdfs1.demo.local
ssh root@hdfs2.demo.local
ssh root@hdfs3.demo.local

cat /root/.ssh/id_rsa   
##Copy into a txt file on desktop and save


Name cluster - HDP
Select stack



##Host to deploy
hdfs1.demo.local
hdfs2.demo.local
hdfs3.demo.local

##on Ambari server, NO isilon yet

Select ssh key file from above
Register and confirm


*********************
rhel 7 has seen a known issue, if hosts fail to register and throws an SSL error with openssl, EOF violation of protocol
add the following:

vi /etc/ambari-agent/conf/ambari-agent.ini


[security]
force_https_protocol=PROTOCOL_TLSv1_2


ambari-server restart
ambari-agent restart
*********************





All hosts green
BACK <---
Select Perform Manual
Add the isilon Sczonehost name in to list; isilonsczone-hdp.demo.local
Register

All host + isilon are now green
continue


Select service to deploy
Move namenode to isilon host
Move snamenode to isilon host

move all other roles around to balance


on roles, master & slaves

datanode - ISILON host only!!
add other roles, client and master to other nodes, nothing else on isilon


##Customize Services
on HDFS configuration, customize:
dfs.namenode.http-address  change port from 50070 --> 8082
dfs.namenode.https-address change port from 50470 --> 8080
##dfs.client-write-packet-size to 131072
yarn.scheduler.capacity.node-locality-delay  to  0  



add all passwords in
continue and deploy --- >


##Test:
hadoop fs -ls /
hadoop fs -mkdir /user/hdfs/TEST50070


or just run the service check!!!!!

cd /usr/hdp/2.3.6.0-3796/hadoop-mapreduce  (the version number may differ)

yarn jar hadoop-mapreduce-examples-2.7.1.2.3.6.0-3796.jar pi 10 100

yarn jar hadoop-mapreduce-examples-2.7.1.2.3.6.0-3796.jar teragen 100000 /user/hdfs/teragenOUT
yarn jar hadoop-mapreduce-examples-2.7.1.2.3.6.0-3796.jar  terasort /user/hdfs/teragenOUT /user/hdfs/terasortOUT
yarn jar hadoop-mapreduce-examples-2.7.1.2.3.6.0-3796.jar  teravalidate /user/hdfs/terasortOUT /user/hdfs/teravalidateOUT




Just the isilon commands in one block:
#################################################################################
#################################################################################



###old version of OneFS
isi license activate --key ISILO-HJXC0-H15JU-YTZTW-OKZLT
isi license activate --key ISILO-HVOC0-PHOJU-YPATW-W4FKT

###New version use trail keys


###License before running


isi zone zones create --name=zone1-hdp --path=/ifs/zone1/hdp --create-path
mkdir -p /ifs/zone1/hdp/hadoop-root
isi network subnets modify groupnet0.subnet0 --sc-service-addr=192.168.1.100
isi network pools create --id=groupnet0:subnet0:hadoop-pool-hdp --ranges=192.168.1.60-192.168.1.68  --access-zone=zone1-hdp  --alloc-method=dynamic  --ifaces=1-4:ext-1 --sc-subnet=subnet0  --sc-dns-zone=isilonsczone-hdp.demo.local    --description=hdp_hadoop_access_zone
isi hdfs settings modify --zone=zone1-hdp --root-directory=/ifs/zone1/hdp/hadoop-root
isi zone zones modify --user-mapping-rules="hdfs=>root" --zone=zone1-hdp
touch /ifs/zone1/hdp/hadoop-root/THIS_IS_ISILON_zone1-hdp.txt
isi auth settings acls modify --group-owner-inheritance=parent
mkdir -p /ifs/zone1/hdp/scripts
cd /ifs/zone1/hdp/scripts
wget https://raw.githubusercontent.com/Isilon/isilon_hadoop_tools/master/isilon_create_users.sh --no-check-certificate
wget https://raw.githubusercontent.com/Isilon/isilon_hadoop_tools/master/isilon_create_directories.sh --no-check-certificate
chmod u+x *
bash isilon_create_users.sh --dist hwx --startuid 501 --startgid 501  --zone zone1-hdp
bash isilon_create_directories.sh --dist hwx --zone zone1-hdp  --fixperm
isi hdfs settings modify --zone=zone1-hdp --ambari-namenode=isilonsczone-hdp.demo.local




##Need to have created the SCZone before running
isi hdfs settings modify --zone=zone1-hdp --ambari-server=hdfs01.demo.local


##IF AD, chnage domain name to your domain
isi zone zones modify --user-mapping-rules="hdfs=>root, demo\hdfs=>root, demo\* &= *[], demo\* += *[group], demo\* += *[groups]" --zone=zone1-hdp



isi license list
isi zone zones list --verbose
isi network subnets list --verbose
isi network pools list --verbose
isi network pools view --id=groupnet0:subnet0:hadoop-pool-hdp
isi hdfs settings view --zone=zone1-hdp
ls -al /ifs/zone1/hdp/hadoop-root
ls -al /ifs/zone1/hdp/hadoop-root/user
cat /ifs/zone1/cdh/scripts/zone1-hdp.passwd
cat /ifs/zone1/cdh/scripts/zone1-hdp.group

#################################################################################
#################################################################################